{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "x = []\n",
    "for i in range(100):\n",
    "    x.append([[i+j] for j in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0], [1], [2], [3], [4]],\n",
       " [[1], [2], [3], [4], [5]],\n",
       " [[2], [3], [4], [5], [6]],\n",
       " [[3], [4], [5], [6], [7]],\n",
       " [[4], [5], [6], [7], [8]],\n",
       " [[5], [6], [7], [8], [9]],\n",
       " [[6], [7], [8], [9], [10]],\n",
       " [[7], [8], [9], [10], [11]],\n",
       " [[8], [9], [10], [11], [12]],\n",
       " [[9], [10], [11], [12], [13]]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "y = []\n",
    "for i in range(100):\n",
    "    y.append(i+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into arrays\n",
    "x, y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x, y = x/100, y/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 5, 1), (100,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(1, batch_input_shape=(None, 5, 1), return_sequences=True),\n",
    "    tf.keras.layers.LSTM(1, return_sequences=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "80/80 [==============================] - 4s 55ms/sample - loss: 0.1657 - accuracy: 0.0000e+00 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.1613 - accuracy: 0.0000e+00 - val_loss: 0.1871 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.1564 - accuracy: 0.0000e+00 - val_loss: 0.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.1521 - accuracy: 0.0000e+00 - val_loss: 0.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.1479 - accuracy: 0.0000e+00 - val_loss: 0.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.1436 - accuracy: 0.0000e+00 - val_loss: 0.1671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.1396 - accuracy: 0.0000e+00 - val_loss: 0.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.1357 - accuracy: 0.0000e+00 - val_loss: 0.1579 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.1319 - accuracy: 0.0000e+00 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.1284 - accuracy: 0.0000e+00 - val_loss: 0.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.1248 - accuracy: 0.0000e+00 - val_loss: 0.1454 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.1215 - accuracy: 0.0000e+00 - val_loss: 0.1415 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.1182 - accuracy: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.1152 - accuracy: 0.0000e+00 - val_loss: 0.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.1122 - accuracy: 0.0000e+00 - val_loss: 0.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.1094 - accuracy: 0.0000e+00 - val_loss: 0.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.1068 - accuracy: 0.0000e+00 - val_loss: 0.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 0.1042 - accuracy: 0.0000e+00 - val_loss: 0.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.1017 - accuracy: 0.0000e+00 - val_loss: 0.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0994 - accuracy: 0.0000e+00 - val_loss: 0.1160 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0972 - accuracy: 0.0000e+00 - val_loss: 0.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0951 - accuracy: 0.0000e+00 - val_loss: 0.1109 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0930 - accuracy: 0.0000e+00 - val_loss: 0.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.0911 - accuracy: 0.0000e+00 - val_loss: 0.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0892 - accuracy: 0.0000e+00 - val_loss: 0.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0875 - accuracy: 0.0000e+00 - val_loss: 0.1019 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/400\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 0.0859 - accuracy: 0.0000e+00 - val_loss: 0.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0842 - accuracy: 0.0000e+00 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/400\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.0826 - accuracy: 0.0000e+00 - val_loss: 0.0961 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0812 - accuracy: 0.0000e+00 - val_loss: 0.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0798 - accuracy: 0.0000e+00 - val_loss: 0.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/400\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 0.0785 - accuracy: 0.0000e+00 - val_loss: 0.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0772 - accuracy: 0.0000e+00 - val_loss: 0.0893 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0759 - accuracy: 0.0000e+00 - val_loss: 0.0878 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/400\n",
      "80/80 [==============================] - 0s 418us/sample - loss: 0.0748 - accuracy: 0.0000e+00 - val_loss: 0.0864 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0736 - accuracy: 0.0000e+00 - val_loss: 0.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0726 - accuracy: 0.0000e+00 - val_loss: 0.0836 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0715 - accuracy: 0.0000e+00 - val_loss: 0.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0705 - accuracy: 0.0000e+00 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0696 - accuracy: 0.0000e+00 - val_loss: 0.0798 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0687 - accuracy: 0.0000e+00 - val_loss: 0.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0678 - accuracy: 0.0000e+00 - val_loss: 0.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0670 - accuracy: 0.0000e+00 - val_loss: 0.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0662 - accuracy: 0.0000e+00 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0654 - accuracy: 0.0000e+00 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/400\n",
      "80/80 [==============================] - 0s 636us/sample - loss: 0.0647 - accuracy: 0.0000e+00 - val_loss: 0.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/400\n",
      "80/80 [==============================] - 0s 611us/sample - loss: 0.0639 - accuracy: 0.0000e+00 - val_loss: 0.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0632 - accuracy: 0.0000e+00 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0626 - accuracy: 0.0000e+00 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0619 - accuracy: 0.0000e+00 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/400\n",
      "80/80 [==============================] - 0s 573us/sample - loss: 0.0612 - accuracy: 0.0000e+00 - val_loss: 0.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0606 - accuracy: 0.0125 - val_loss: 0.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0600 - accuracy: 0.0125 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0594 - accuracy: 0.0125 - val_loss: 0.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0588 - accuracy: 0.0125 - val_loss: 0.0659 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/400\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.0583 - accuracy: 0.0125 - val_loss: 0.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0578 - accuracy: 0.0125 - val_loss: 0.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0572 - accuracy: 0.0125 - val_loss: 0.0639 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0567 - accuracy: 0.0125 - val_loss: 0.0632 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0563 - accuracy: 0.0125 - val_loss: 0.0626 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0557 - accuracy: 0.0125 - val_loss: 0.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0553 - accuracy: 0.0125 - val_loss: 0.0614 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0548 - accuracy: 0.0125 - val_loss: 0.0607 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0543 - accuracy: 0.0125 - val_loss: 0.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0539 - accuracy: 0.0125 - val_loss: 0.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0534 - accuracy: 0.0125 - val_loss: 0.0589 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0529 - accuracy: 0.0125 - val_loss: 0.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0525 - accuracy: 0.0125 - val_loss: 0.0578 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0521 - accuracy: 0.0125 - val_loss: 0.0572 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0517 - accuracy: 0.0125 - val_loss: 0.0567 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/400\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 0.0512 - accuracy: 0.0125 - val_loss: 0.0561 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0508 - accuracy: 0.0125 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0504 - accuracy: 0.0125 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/400\n",
      "80/80 [==============================] - 0s 817us/sample - loss: 0.0500 - accuracy: 0.0125 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/400\n",
      "80/80 [==============================] - 0s 879us/sample - loss: 0.0496 - accuracy: 0.0125 - val_loss: 0.0542 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/400\n",
      "80/80 [==============================] - 0s 623us/sample - loss: 0.0493 - accuracy: 0.0125 - val_loss: 0.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/400\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.0489 - accuracy: 0.0125 - val_loss: 0.0533 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0485 - accuracy: 0.0125 - val_loss: 0.0529 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/400\n",
      "80/80 [==============================] - 0s 636us/sample - loss: 0.0481 - accuracy: 0.0125 - val_loss: 0.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0477 - accuracy: 0.0125 - val_loss: 0.0520 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0474 - accuracy: 0.0125 - val_loss: 0.0515 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0470 - accuracy: 0.0125 - val_loss: 0.0511 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0466 - accuracy: 0.0125 - val_loss: 0.0507 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0462 - accuracy: 0.0125 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/400\n",
      "80/80 [==============================] - 0s 785us/sample - loss: 0.0458 - accuracy: 0.0125 - val_loss: 0.0498 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0455 - accuracy: 0.0125 - val_loss: 0.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0451 - accuracy: 0.0125 - val_loss: 0.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0447 - accuracy: 0.0125 - val_loss: 0.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0444 - accuracy: 0.0125 - val_loss: 0.0481 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0440 - accuracy: 0.0125 - val_loss: 0.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/400\n",
      "80/80 [==============================] - 0s 823us/sample - loss: 0.0436 - accuracy: 0.0125 - val_loss: 0.0473 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/400\n",
      "80/80 [==============================] - 0s 473us/sample - loss: 0.0433 - accuracy: 0.0125 - val_loss: 0.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0429 - accuracy: 0.0125 - val_loss: 0.0465 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0425 - accuracy: 0.0125 - val_loss: 0.0461 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/400\n",
      "80/80 [==============================] - 0s 717us/sample - loss: 0.0422 - accuracy: 0.0125 - val_loss: 0.0457 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0418 - accuracy: 0.0125 - val_loss: 0.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0414 - accuracy: 0.0125 - val_loss: 0.0449 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0411 - accuracy: 0.0125 - val_loss: 0.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0407 - accuracy: 0.0125 - val_loss: 0.0442 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0404 - accuracy: 0.0125 - val_loss: 0.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0400 - accuracy: 0.0125 - val_loss: 0.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0397 - accuracy: 0.0125 - val_loss: 0.0431 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0393 - accuracy: 0.0125 - val_loss: 0.0427 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0390 - accuracy: 0.0125 - val_loss: 0.0424 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0386 - accuracy: 0.0125 - val_loss: 0.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0383 - accuracy: 0.0125 - val_loss: 0.0417 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/400\n",
      "80/80 [==============================] - 0s 686us/sample - loss: 0.0379 - accuracy: 0.0125 - val_loss: 0.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/400\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 0.0376 - accuracy: 0.0125 - val_loss: 0.0409 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0372 - accuracy: 0.0125 - val_loss: 0.0406 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/400\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.0369 - accuracy: 0.0125 - val_loss: 0.0402 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0365 - accuracy: 0.0125 - val_loss: 0.0399 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0362 - accuracy: 0.0125 - val_loss: 0.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0359 - accuracy: 0.0125 - val_loss: 0.0392 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0355 - accuracy: 0.0125 - val_loss: 0.0389 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0352 - accuracy: 0.0125 - val_loss: 0.0385 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0348 - accuracy: 0.0125 - val_loss: 0.0382 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0345 - accuracy: 0.0125 - val_loss: 0.0378 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0342 - accuracy: 0.0125 - val_loss: 0.0375 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/400\n",
      "80/80 [==============================] - 0s 573us/sample - loss: 0.0339 - accuracy: 0.0125 - val_loss: 0.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0335 - accuracy: 0.0125 - val_loss: 0.0368 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0332 - accuracy: 0.0125 - val_loss: 0.0365 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/400\n",
      "80/80 [==============================] - 0s 524us/sample - loss: 0.0329 - accuracy: 0.0125 - val_loss: 0.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/400\n",
      "80/80 [==============================] - 0s 598us/sample - loss: 0.0325 - accuracy: 0.0125 - val_loss: 0.0358 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0322 - accuracy: 0.0125 - val_loss: 0.0355 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0319 - accuracy: 0.0125 - val_loss: 0.0351 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0316 - accuracy: 0.0125 - val_loss: 0.0348 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0313 - accuracy: 0.0125 - val_loss: 0.0345 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0310 - accuracy: 0.0125 - val_loss: 0.0342 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0306 - accuracy: 0.0125 - val_loss: 0.0338 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0304 - accuracy: 0.0125 - val_loss: 0.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0300 - accuracy: 0.0125 - val_loss: 0.0332 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0298 - accuracy: 0.0125 - val_loss: 0.0329 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/400\n",
      "80/80 [==============================] - 0s 879us/sample - loss: 0.0295 - accuracy: 0.0125 - val_loss: 0.0326 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/400\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.0292 - accuracy: 0.0125 - val_loss: 0.0323 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/400\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.0289 - accuracy: 0.0125 - val_loss: 0.0320 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/400\n",
      "80/80 [==============================] - 0s 860us/sample - loss: 0.0286 - accuracy: 0.0125 - val_loss: 0.0317 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/400\n",
      "80/80 [==============================] - 0s 524us/sample - loss: 0.0283 - accuracy: 0.0125 - val_loss: 0.0314 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0280 - accuracy: 0.0125 - val_loss: 0.0311 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/400\n",
      "80/80 [==============================] - 0s 536us/sample - loss: 0.0277 - accuracy: 0.0125 - val_loss: 0.0308 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0275 - accuracy: 0.0125 - val_loss: 0.0305 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0272 - accuracy: 0.0125 - val_loss: 0.0302 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/400\n",
      "80/80 [==============================] - 0s 530us/sample - loss: 0.0269 - accuracy: 0.0125 - val_loss: 0.0299 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0266 - accuracy: 0.0125 - val_loss: 0.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/400\n",
      "80/80 [==============================] - 0s 530us/sample - loss: 0.0264 - accuracy: 0.0125 - val_loss: 0.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0261 - accuracy: 0.0125 - val_loss: 0.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0259 - accuracy: 0.0125 - val_loss: 0.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/400\n",
      "80/80 [==============================] - 0s 480us/sample - loss: 0.0256 - accuracy: 0.0125 - val_loss: 0.0286 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/400\n",
      "80/80 [==============================] - 0s 611us/sample - loss: 0.0254 - accuracy: 0.0125 - val_loss: 0.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0251 - accuracy: 0.0125 - val_loss: 0.0280 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0249 - accuracy: 0.0125 - val_loss: 0.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/400\n",
      "80/80 [==============================] - 0s 611us/sample - loss: 0.0247 - accuracy: 0.0125 - val_loss: 0.0275 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/400\n",
      "80/80 [==============================] - 0s 598us/sample - loss: 0.0244 - accuracy: 0.0125 - val_loss: 0.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/400\n",
      "80/80 [==============================] - 0s 1ms/sample - loss: 0.0242 - accuracy: 0.0125 - val_loss: 0.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.0000e+ - 0s 1ms/sample - loss: 0.0240 - accuracy: 0.0125 - val_loss: 0.0268 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/400\n",
      "80/80 [==============================] - 0s 823us/sample - loss: 0.0237 - accuracy: 0.0125 - val_loss: 0.0265 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/400\n",
      "80/80 [==============================] - 0s 673us/sample - loss: 0.0235 - accuracy: 0.0125 - val_loss: 0.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0233 - accuracy: 0.0125 - val_loss: 0.0260 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0231 - accuracy: 0.0125 - val_loss: 0.0258 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0229 - accuracy: 0.0125 - val_loss: 0.0256 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0227 - accuracy: 0.0125 - val_loss: 0.0253 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0225 - accuracy: 0.0125 - val_loss: 0.0251 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/400\n",
      "80/80 [==============================] - 0s 530us/sample - loss: 0.0223 - accuracy: 0.0125 - val_loss: 0.0249 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0221 - accuracy: 0.0125 - val_loss: 0.0247 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/400\n",
      "80/80 [==============================] - 0s 598us/sample - loss: 0.0219 - accuracy: 0.0125 - val_loss: 0.0245 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/400\n",
      "80/80 [==============================] - 0s 549us/sample - loss: 0.0217 - accuracy: 0.0125 - val_loss: 0.0242 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/400\n",
      "80/80 [==============================] - 0s 623us/sample - loss: 0.0215 - accuracy: 0.0125 - val_loss: 0.0240 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/400\n",
      "80/80 [==============================] - 0s 549us/sample - loss: 0.0213 - accuracy: 0.0125 - val_loss: 0.0238 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/400\n",
      "80/80 [==============================] - 0s 573us/sample - loss: 0.0211 - accuracy: 0.0125 - val_loss: 0.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0210 - accuracy: 0.0125 - val_loss: 0.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0208 - accuracy: 0.0125 - val_loss: 0.0232 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0206 - accuracy: 0.0125 - val_loss: 0.0230 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0204 - accuracy: 0.0125 - val_loss: 0.0228 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0203 - accuracy: 0.0125 - val_loss: 0.0226 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/400\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 0.0201 - accuracy: 0.0125 - val_loss: 0.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0199 - accuracy: 0.0125 - val_loss: 0.0223 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0198 - accuracy: 0.0125 - val_loss: 0.0221 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0196 - accuracy: 0.0125 - val_loss: 0.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0195 - accuracy: 0.0125 - val_loss: 0.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0193 - accuracy: 0.0125 - val_loss: 0.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0192 - accuracy: 0.0125 - val_loss: 0.0214 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0190 - accuracy: 0.0125 - val_loss: 0.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/400\n",
      "80/80 [==============================] - 0s 549us/sample - loss: 0.0189 - accuracy: 0.0125 - val_loss: 0.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/400\n",
      "80/80 [==============================] - 0s 536us/sample - loss: 0.0187 - accuracy: 0.0125 - val_loss: 0.0209 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0186 - accuracy: 0.0125 - val_loss: 0.0207 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0185 - accuracy: 0.0125 - val_loss: 0.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0183 - accuracy: 0.0125 - val_loss: 0.0204 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/400\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.0182 - accuracy: 0.0125 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0180 - accuracy: 0.0125 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0179 - accuracy: 0.0125 - val_loss: 0.0199 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0178 - accuracy: 0.0125 - val_loss: 0.0197 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/400\n",
      "80/80 [==============================] - 0s 549us/sample - loss: 0.0177 - accuracy: 0.0125 - val_loss: 0.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0175 - accuracy: 0.0125 - val_loss: 0.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0174 - accuracy: 0.0125 - val_loss: 0.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0173 - accuracy: 0.0125 - val_loss: 0.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0172 - accuracy: 0.0125 - val_loss: 0.0190 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0170 - accuracy: 0.0125 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0169 - accuracy: 0.0125 - val_loss: 0.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0168 - accuracy: 0.0125 - val_loss: 0.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/400\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.0000e+ - 0s 399us/sample - loss: 0.0167 - accuracy: 0.0125 - val_loss: 0.0185 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0166 - accuracy: 0.0125 - val_loss: 0.0183 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0165 - accuracy: 0.0125 - val_loss: 0.0182 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0164 - accuracy: 0.0125 - val_loss: 0.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/400\n",
      "80/80 [==============================] - 0s 415us/sample - loss: 0.0163 - accuracy: 0.0125 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0162 - accuracy: 0.0125 - val_loss: 0.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0161 - accuracy: 0.0125 - val_loss: 0.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/400\n",
      "80/80 [==============================] - 0s 380us/sample - loss: 0.0160 - accuracy: 0.0125 - val_loss: 0.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0159 - accuracy: 0.0125 - val_loss: 0.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0159 - accuracy: 0.0125 - val_loss: 0.0174 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/400\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 0.0158 - accuracy: 0.0125 - val_loss: 0.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0157 - accuracy: 0.0125 - val_loss: 0.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0156 - accuracy: 0.0125 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0155 - accuracy: 0.0125 - val_loss: 0.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0154 - accuracy: 0.0125 - val_loss: 0.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0153 - accuracy: 0.0125 - val_loss: 0.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0152 - accuracy: 0.0125 - val_loss: 0.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0152 - accuracy: 0.0125 - val_loss: 0.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0151 - accuracy: 0.0125 - val_loss: 0.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0150 - accuracy: 0.0125 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0149 - accuracy: 0.0125 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0148 - accuracy: 0.0125 - val_loss: 0.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0148 - accuracy: 0.0125 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0147 - accuracy: 0.0125 - val_loss: 0.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0146 - accuracy: 0.0125 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0146 - accuracy: 0.0125 - val_loss: 0.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0145 - accuracy: 0.0125 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0144 - accuracy: 0.0125 - val_loss: 0.0157 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0143 - accuracy: 0.0125 - val_loss: 0.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0143 - accuracy: 0.0125 - val_loss: 0.0155 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0142 - accuracy: 0.0125 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0141 - accuracy: 0.0125 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0141 - accuracy: 0.0125 - val_loss: 0.0153 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0140 - accuracy: 0.0125 - val_loss: 0.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0139 - accuracy: 0.0125 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0139 - accuracy: 0.0125 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0138 - accuracy: 0.0125 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0137 - accuracy: 0.0125 - val_loss: 0.0149 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0137 - accuracy: 0.0125 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0136 - accuracy: 0.0125 - val_loss: 0.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0135 - accuracy: 0.0125 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0135 - accuracy: 0.0125 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0134 - accuracy: 0.0125 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0134 - accuracy: 0.0125 - val_loss: 0.0144 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0133 - accuracy: 0.0125 - val_loss: 0.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0132 - accuracy: 0.0125 - val_loss: 0.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0132 - accuracy: 0.0125 - val_loss: 0.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0131 - accuracy: 0.0125 - val_loss: 0.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0131 - accuracy: 0.0125 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/400\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.0130 - accuracy: 0.0125 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0129 - accuracy: 0.0125 - val_loss: 0.0139 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0129 - accuracy: 0.0125 - val_loss: 0.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/400\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.0128 - accuracy: 0.0125 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0128 - accuracy: 0.0125 - val_loss: 0.0137 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0127 - accuracy: 0.0125 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/400\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.0127 - accuracy: 0.0125 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0126 - accuracy: 0.0125 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0126 - accuracy: 0.0125 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0125 - accuracy: 0.0125 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0125 - accuracy: 0.0125 - val_loss: 0.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0124 - accuracy: 0.0125 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0123 - accuracy: 0.0125 - val_loss: 0.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0123 - accuracy: 0.0125 - val_loss: 0.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0122 - accuracy: 0.0125 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0122 - accuracy: 0.0125 - val_loss: 0.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0121 - accuracy: 0.0125 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0121 - accuracy: 0.0125 - val_loss: 0.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0120 - accuracy: 0.0125 - val_loss: 0.0128 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0120 - accuracy: 0.0125 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0120 - accuracy: 0.0125 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0119 - accuracy: 0.0125 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0119 - accuracy: 0.0125 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0118 - accuracy: 0.0125 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0118 - accuracy: 0.0125 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0117 - accuracy: 0.0125 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/400\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.0117 - accuracy: 0.0125 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/400\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.0116 - accuracy: 0.0125 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0116 - accuracy: 0.0125 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0115 - accuracy: 0.0125 - val_loss: 0.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0115 - accuracy: 0.0125 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0114 - accuracy: 0.0125 - val_loss: 0.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0114 - accuracy: 0.0125 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0114 - accuracy: 0.0125 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0113 - accuracy: 0.0125 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0113 - accuracy: 0.0125 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/400\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.0112 - accuracy: 0.0125 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0112 - accuracy: 0.0125 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0112 - accuracy: 0.0125 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/400\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.0111 - accuracy: 0.0125 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0111 - accuracy: 0.0125 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0110 - accuracy: 0.0125 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0110 - accuracy: 0.0125 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0109 - accuracy: 0.0125 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0109 - accuracy: 0.0125 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/400\n",
      "80/80 [==============================] - 0s 427us/sample - loss: 0.0109 - accuracy: 0.0125 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0108 - accuracy: 0.0125 - val_loss: 0.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0108 - accuracy: 0.0125 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/400\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.0107 - accuracy: 0.0125 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0107 - accuracy: 0.0125 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0107 - accuracy: 0.0125 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0106 - accuracy: 0.0125 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0106 - accuracy: 0.0125 - val_loss: 0.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0105 - accuracy: 0.0125 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0105 - accuracy: 0.0125 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0105 - accuracy: 0.0125 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0104 - accuracy: 0.0125 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0104 - accuracy: 0.0125 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0103 - accuracy: 0.0125 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0103 - accuracy: 0.0125 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0103 - accuracy: 0.0125 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0102 - accuracy: 0.0125 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0102 - accuracy: 0.0125 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0102 - accuracy: 0.0125 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0101 - accuracy: 0.0125 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0101 - accuracy: 0.0125 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/400\n",
      "80/80 [==============================] - 0s 418us/sample - loss: 0.0100 - accuracy: 0.0125 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0100 - accuracy: 0.0125 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0100 - accuracy: 0.0125 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0099 - accuracy: 0.0125 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0099 - accuracy: 0.0125 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0099 - accuracy: 0.0125 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0098 - accuracy: 0.0125 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0098 - accuracy: 0.0125 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0098 - accuracy: 0.0125 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0097 - accuracy: 0.0125 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0097 - accuracy: 0.0125 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0097 - accuracy: 0.0125 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0096 - accuracy: 0.0125 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0096 - accuracy: 0.0125 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0095 - accuracy: 0.0125 - val_loss: 0.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0095 - accuracy: 0.0125 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0095 - accuracy: 0.0125 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/400\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.0095 - accuracy: 0.0125 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0094 - accuracy: 0.0125 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0094 - accuracy: 0.0125 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0094 - accuracy: 0.0125 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/400\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.0093 - accuracy: 0.0125 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0093 - accuracy: 0.0125 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0093 - accuracy: 0.0125 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/400\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.0092 - accuracy: 0.0125 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0092 - accuracy: 0.0125 - val_loss: 0.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0092 - accuracy: 0.0125 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/400\n",
      "80/80 [==============================] - 0s 393us/sample - loss: 0.0091 - accuracy: 0.0125 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0091 - accuracy: 0.0125 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0091 - accuracy: 0.0125 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0090 - accuracy: 0.0125 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0090 - accuracy: 0.0125 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/400\n",
      "80/80 [==============================] - 0s 524us/sample - loss: 0.0090 - accuracy: 0.0125 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0089 - accuracy: 0.0125 - val_loss: 0.0091 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0089 - accuracy: 0.0125 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0089 - accuracy: 0.0125 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0088 - accuracy: 0.0125 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0088 - accuracy: 0.0125 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0088 - accuracy: 0.0125 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0087 - accuracy: 0.0125 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0087 - accuracy: 0.0125 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0087 - accuracy: 0.0125 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/400\n",
      "80/80 [==============================] - 0s 636us/sample - loss: 0.0087 - accuracy: 0.0125 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/400\n",
      "80/80 [==============================] - 0s 611us/sample - loss: 0.0086 - accuracy: 0.0125 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/400\n",
      "80/80 [==============================] - 0s 586us/sample - loss: 0.0086 - accuracy: 0.0125 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/400\n",
      "80/80 [==============================] - 0s 518us/sample - loss: 0.0086 - accuracy: 0.0125 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/400\n",
      "80/80 [==============================] - 0s 524us/sample - loss: 0.0085 - accuracy: 0.0125 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/400\n",
      "80/80 [==============================] - 0s 480us/sample - loss: 0.0085 - accuracy: 0.0125 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0085 - accuracy: 0.0125 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0085 - accuracy: 0.0125 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/400\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.0084 - accuracy: 0.0125 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0084 - accuracy: 0.0125 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0084 - accuracy: 0.0125 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0083 - accuracy: 0.0125 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0083 - accuracy: 0.0125 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/400\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 0.0083 - accuracy: 0.0125 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0082 - accuracy: 0.0125 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0082 - accuracy: 0.0125 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/400\n",
      "80/80 [==============================] - 0s 404us/sample - loss: 0.0082 - accuracy: 0.0125 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/400\n",
      "80/80 [==============================] - 0s 486us/sample - loss: 0.0082 - accuracy: 0.0125 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/400\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.0081 - accuracy: 0.0125 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/400\n",
      "80/80 [==============================] - 0s 505us/sample - loss: 0.0081 - accuracy: 0.0125 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0081 - accuracy: 0.0125 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/400\n",
      "80/80 [==============================] - 0s 530us/sample - loss: 0.0081 - accuracy: 0.0125 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/400\n",
      "80/80 [==============================] - 0s 573us/sample - loss: 0.0080 - accuracy: 0.0125 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/400\n",
      "80/80 [==============================] - 0s 580us/sample - loss: 0.0080 - accuracy: 0.0125 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/400\n",
      "80/80 [==============================] - 0s 536us/sample - loss: 0.0080 - accuracy: 0.0125 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/400\n",
      "80/80 [==============================] - 0s 517us/sample - loss: 0.0079 - accuracy: 0.0125 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0079 - accuracy: 0.0125 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0079 - accuracy: 0.0125 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/400\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.0079 - accuracy: 0.0125 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/400\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 0.0078 - accuracy: 0.0125 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0078 - accuracy: 0.0125 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/400\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.0078 - accuracy: 0.0125 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/400\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.0078 - accuracy: 0.0125 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0077 - accuracy: 0.0125 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/400\n",
      "80/80 [==============================] - 0s 586us/sample - loss: 0.0077 - accuracy: 0.0125 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/400\n",
      "80/80 [==============================] - 0s 623us/sample - loss: 0.0077 - accuracy: 0.0125 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/400\n",
      "80/80 [==============================] - 0s 536us/sample - loss: 0.0077 - accuracy: 0.0125 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/400\n",
      "80/80 [==============================] - 0s 561us/sample - loss: 0.0076 - accuracy: 0.0125 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/400\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 0.0076 - accuracy: 0.0125 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/400\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.0076 - accuracy: 0.0125 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0076 - accuracy: 0.0125 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0075 - accuracy: 0.0125 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/400\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.0075 - accuracy: 0.0125 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/400\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.0075 - accuracy: 0.0125 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/400\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.0075 - accuracy: 0.0125 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Trining\n",
    "history = model.fit(x_train, y_train, epochs=400, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7595181 ],\n",
       "       [0.76867384],\n",
       "       [0.4194263 ],\n",
       "       [0.7619476 ],\n",
       "       [0.78464437],\n",
       "       [0.19761744],\n",
       "       [0.45956722],\n",
       "       [0.7642808 ],\n",
       "       [0.7250176 ],\n",
       "       [0.70799077]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85, 0.89, 0.38, 0.86, 0.98, 0.22, 0.41, 0.87, 0.74, 0.7 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "plt.scatter(range(len(y_test)), predictions, c='r')\n",
    "plt.scatter(range(len(y_test)), y_test, c='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
